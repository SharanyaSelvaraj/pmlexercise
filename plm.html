# Load the required libraries

library(caret)
library(randomForest)
library(rpart) 
library(rpart.plot)
find.package('rpart')
library(RColorBrewer)
install.packages("rattle")

# Set the seed to a random value

set.seed(1234)

#Load the testing and training dataset

training <- read.csv("C:/Users/sharanya/Downloads/pml-training.csv", na.strings=c("NA","#DIV/0!",""))
testing <- read.csv("C:/Users/sharanya/Downloads/pml-testing.csv", na.strings=c("NA","#DIV/0!",""))

# Create the 10 fold cross validation with repetitions

train_control <- trainControl(method="repeatedcv", number=10, repeats=3)

# check the dimensions of testing and training set
           
myTraining <- training[inTrain, ]; 
myTesting <- training[-inTrain, ]
dim(myTraining); 
dim(myTesting)
             
# Eliminate the near to zero values from every column as they may not be much useful
             
myDataNZV <- neartrain.control <- trainControl(method = "cv", number = 10)ZeroVar(myTraining, saveMetrics=TRUE)
myNZVvars <- names(myTraining) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt",
+ "kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt",
+ "max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm",
+ "var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm",
+ "stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm",
+ "kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
+ "max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm",
+ "kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
+ "skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",
+ "amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm",
+ "skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm",
+ "max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm",
+ "amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
+ "avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm",
+ "stddev_yaw_forearm", "var_yaw_forearm")
             
            
myTraining <- myTraining[c(-1)]

#creating another subset to iterate in loop
trainingV3 <- myTraining 
              
#for every column in the training dataset. If the columns are same then eliminate or remove them
              
for(i in 1:length(myTraining)) { 
+         if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .6 ) {
+         for(j in 1:length(trainingV3)) {
+             if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) ==1)  {
+                 trainingV3 <- trainingV3[ , -j] 
+             }   
+         } 
+     }
+ }
                                
# clean both the testing and training data
                                
myTraining <- trainingV3
rm(trainingV3)
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58]) 
myTesting <- myTesting[clean1]
testing <- testing[clean2]
  
# Check the dimensions
  
dim(myTesting)
dim(testing)
for (i in 1:length(testing) ) {
+         for(j in 1:length(myTraining)) {
+         if( length( grep(names(myTraining[i]), names(testing)[j]) ) ==1)  {
+             class(testing[j]) <- class(myTraining[i])
+         }      
+     }      
+ }
testing <- rbind(myTraining[2, -58] , testing) 
testing <- testing[-1,]
           
# fit the model named A1 that does predictions. This is a model with no specific machine learning algorithm. This is built with just a call to predict()
modFitA1 <- rpart(classe ~ ., data=train.control, method="class")
predictionsA1 <- predict(modFitA1, train.control, type = "class")
                 
# display the predictions using confusion matrix
confusionMatrix(predictionsA1, train.control$classe)
                 
   Reference
   Prediction    A    B    C    D    E
         A 2157   68   10    1    0
         B   60 1265   73   67    0
         C   15  177 1261  141   70
         D    0    8   15  962  111
         E    0    0    9  115 1261
Overall Statistics

Accuracy : 0.8802          
                 95% CI : (0.8728, 0.8873)
    No Information Rate : 0.2845          
    P-Value [Acc> NIR] : < 2.2e-16       

Kappa : 0.8484          

Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9664   0.8333   0.9218   0.7481   0.8745
Specificity            0.9859   0.9684   0.9378   0.9796   0.9806
PosPred Value         0.9647   0.8635   0.7578   0.8777   0.9105
NegPred Value         0.9866   0.9604   0.9827   0.9520   0.9720
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2749   0.1612   0.1607   0.1226   0.1607
Detection Prevalence   0.2850   0.1867   0.2121   0.1397   0.1765
Balanced Accuracy      0.9762   0.9009   0.9298   0.8638   0.9276c                 
# The model do not show promising result, since it is built using the predict() without specific algorithm
 
# Second model: Random forest           
library(randomForest)
randomForest

# Fit the random forest model             
modFitB1 <- randomForest(classe ~. , data=train.control)
predictionsB1 <- predict(modFitB1, train.control, type = "class")
         
# Display the confusion matrix           
confusionMatrix(predictionsB1, train.control$classe)

Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 2232    5    0    0    0
         B    0 1513    2    0    0
         C    0    0 1362    7    0
         D    0    0    4 1278    1
         E    0    0    0    1 1441

Overall Statistics

Accuracy : 0.9975          
                 95% CI : (0.9961, 0.9984)
    No Information Rate : 0.2845          
    P-Value [Acc> NIR] : < 2.2e-16       

Kappa : 0.9968          

Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9967   0.9956   0.9938   0.9993
Specificity            0.9991   0.9997   0.9989   0.9992   0.9998
PosPred Value         0.9978   0.9987   0.9949   0.9961   0.9993
NegPred Value         1.0000   0.9992   0.9991   0.9988   0.9998
Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
Detection Rate         0.2845   0.1928   0.1736   0.1629   0.1837
Detection Prevalence   0.2851   0.1931   0.1745   0.1635   0.1838
Balanced Accuracy      0.9996   0.9982   0.9973   0.9965   0.9996           

# Create a file B2 that stores the above values
pml_write_files = function(x){
+   n = length(x)
+   for(i in 1:n){
+     filename = paste0("problem_id_",i,".txt")
+     write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
+   }
+ }
pml_write_files(predictionsB2)
predictionsB2  
                 

                                                
             
